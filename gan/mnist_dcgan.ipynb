{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\",\n",
    "                              train=True,\n",
    "                              download=True,\n",
    "                              transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_size=1, ndf=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.ndf = ndf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(self.in_size, self.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.ndf, self.ndf *2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        h = self.main(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_size=100, out_size=1, ngf=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_size = z_size\n",
    "        self.ngf = ngf\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.z_size, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(self.ngf, self.out_size, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        h = self.main(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator()\n",
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "d_optimizer = torch.optim.Adam(dis.parameters(), lr=lr)\n",
    "g_optimizer = torch.optim.Adam(gen.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(dis, x_real, y_real, x_fake, y_fake):\n",
    "    dis.zero_grad()\n",
    "    print(x_real.shape)\n",
    "    \n",
    "    outputs = dis(x_real)\n",
    "    real_loss = criterion(outputs, y_real)\n",
    "    real_score = outputs\n",
    "    \n",
    "    outputs = dis(x_fake)\n",
    "    fake_loss = criterion(outputs, y_fake)\n",
    "    fake_score = outputs\n",
    "    \n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss, real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(gen, dis_outputs, y_real):\n",
    "    gen.zero_grad()\n",
    "    g_loss = criterion(dis_outputs, y_real)\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = Variable(torch.randn(num_test_samples, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i, j].get_xaxis().set_visible(False)\n",
    "    ax[i, j].get_yaxis().set_visible(False)\n",
    "    \n",
    "num_epochs = 200\n",
    "num_batches = len(train_loader)\n",
    "num_fig = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (images, _) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        y_real = Variable(torch.ones(images.size(0)))\n",
    "        \n",
    "        z = Variable(torch.randn(images.size(0), 100)).view(-1, 100, 1, 1)\n",
    "        x_fake = gen(z)\n",
    "        y_fake = Variable(torch.zeros(images.size(0),))\n",
    "        \n",
    "        d_loss, real_score, fake_score = train_discriminator(dis, images, y_real, x_fake, y_fake)\n",
    "        \n",
    "        z = Variable(torch.randn(images.size(0), 100)).view(-1, 100, 1, 1)\n",
    "        x_fake = gen(z)\n",
    "        outputs = dis(x_fake)\n",
    "        \n",
    "        g_loss = train_generator(gen, outputs, y_real)\n",
    "        \n",
    "        if (n+1) % 100 == 0:\n",
    "            test_images = gen(test_noise)\n",
    "            for k in range(num_test_samples):\n",
    "                i = k // 4\n",
    "                j = k % 4\n",
    "                ax[i, j].cla()\n",
    "                ax[i, j].imshow(test_images[k, :].data.numpy().reshape(28, 28), cmap=\"Greys\")\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            plt.savefig(\"results/%03d.png\" % num_fig)\n",
    "            num_fig += 1\n",
    "            print('Epoch [%d/%d], Step[%d/%d], d_loss: %.4f, g_loss: %.4f, ' \n",
    "                  'D(x): %.2f, D(G(z)): %.2f' \n",
    "                  %(epoch + 1, num_epochs, n+1, num_batches, d_loss.data[0], g_loss.data[0],\n",
    "                    real_score.data.mean(), fake_score.data.mean()))\n",
    "\n",
    "fig.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
